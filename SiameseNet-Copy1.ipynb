{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf  \n",
    "模型定义用的这篇文章里的，损失函数和优化器及超参数策略是自己按照SVM里面的来的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import imageio\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nored(img):\n",
    "    flag = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i, j, 0] > img[i, j, 1] and img[i, j, 0] > img[i, j, 2] and img[i, j, 0] > 100:\n",
    "                flag[i, j] = 1\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if flag[i, j] == 1:\n",
    "                count = 0\n",
    "                new = np.zeros((4, ))\n",
    "                if i > 0:\n",
    "                    if not flag[i - 1, j]:\n",
    "                        new = new + img[i - 1, j, :]\n",
    "                        count = count + 1\n",
    "                if j > 0:\n",
    "                    if not flag[i, j - 1]:\n",
    "                        new = new + img[i, j - 1, :]\n",
    "                        count = count + 1\n",
    "                if i < img.shape[0] - 1:\n",
    "                    if not flag[i + 1, j]:\n",
    "                        new = new + img[i + 1, j, :]\n",
    "                        count = count + 1\n",
    "                if j < img.shape[1] - 1:\n",
    "                    if not flag[i, j + 1]:\n",
    "                        new = new + img[i, j + 1, :]\n",
    "                        count = count + 1\n",
    "                if count != 0:\n",
    "                    img[i, j, :] = new / count\n",
    "                    flag[i, j] = 0\n",
    "    return img\n",
    "\n",
    "with open(\"train.json\", \"r\") as f:\n",
    "    dic = json.loads(f.read())\n",
    "names = list(dic)\n",
    "labels = list(dic.values())\n",
    "num_examples = len(names)\n",
    "for k in range(num_examples):\n",
    "    name = names[k]\n",
    "    label = labels[k]\n",
    "    path = \"Train\\\\\" + label + \"\\\\\" + name\n",
    "    img = imageio.imread(path)\n",
    "    \n",
    "    img = nored(img)\n",
    "    \n",
    "    path = \"grayimg\\\\\" + labels[k] + '.png'\n",
    "    imageio.imwrite(path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.32 sce\n"
     ]
    }
   ],
   "source": [
    "label_to_idx = {\n",
    "    'p1':0, 'p12':1, 'p14':2, 'p17':3, 'p19':4, \n",
    "    'p22':5, 'p25':6, 'p27':7, 'p3':8, 'p6':9, \n",
    "    'p9':10\n",
    "}\n",
    "\n",
    "idx_to_label = [\n",
    "    'p1', 'p12', 'p14', 'p17', 'p19', \n",
    "    'p22', 'p25', 'p27', 'p3', 'p6', \n",
    "    'p9'\n",
    "]\n",
    "\n",
    "# 初始化训练数据\n",
    "def init_train_data():\n",
    "    start = time.time()\n",
    "    with open(\"train.json\", \"r\") as f:\n",
    "        dic = json.loads(f.read())\n",
    "    names = list(dic)\n",
    "    labels = list(dic.values())\n",
    "    num_examples = len(names)\n",
    "    features = []\n",
    "    idx_labels = []\n",
    "    for i in range(num_examples):\n",
    "        name = names[i]\n",
    "        label = labels[i]\n",
    "        path = \"Train\\\\\" + label + \"\\\\\" + name\n",
    "        img = imageio.imread(path)\n",
    "        img = nored(img)\n",
    "        features.append(np.array(img[:, :, 0 : 3]))\n",
    "        idx_labels.append(label_to_idx[label])\n",
    "    print(\"time %.2f sce\" % (time.time() - start))\n",
    "    return features, idx_labels\n",
    "# features 是一个 list，元素为np.array，形状为[宽 * 高 * 3（维度）]\n",
    "\n",
    "features, labels = init_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准尺寸\n",
    "width, height = 105, 105\n",
    "\n",
    "# 设备\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size = 10), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2), \n",
    "            nn.Conv2d(64, 128, kernel_size = 7), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2), \n",
    "            nn.Conv2d(128, 128, kernel_size = 4), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2), \n",
    "            nn.Conv2d(128, 256, kernel_size = 4), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Sequential( \n",
    "            nn.Linear(256 * 6 * 6, 4096), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size = 10), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2), \n",
    "            nn.Conv2d(64, 128, kernel_size = 7), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2), \n",
    "            nn.Conv2d(128, 128, kernel_size = 4), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2), \n",
    "            nn.Conv2d(128, 256, kernel_size = 4), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential( \n",
    "            nn.Linear(256 * 6 * 6, 4096), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Linear(4096, 1), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, img1, img2):\n",
    "        feature11 = self.conv1(img1)\n",
    "        feature12 = self.fc1(feature11.view(img1.shape[0], -1))\n",
    "        feature21 = self.conv2(img2)\n",
    "        feature22 = self.fc2(feature21.view(img2.shape[0], -1))\n",
    "        feature3 = abs(feature12 - feature22)\n",
    "        output = self.fc(feature3)\n",
    "        return output.view((output.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, time 6.01 sec\n",
      "tensor([0, 6, 0, 3, 4, 5, 6, 0, 8, 9, 0], device='cuda:0')\n",
      "epoch 20, time 11.20 sec\n",
      "tensor([0, 1, 0, 0, 4, 0, 6, 0, 1, 9, 0], device='cuda:0')\n",
      "epoch 30, time 16.35 sec\n",
      "tensor([7, 4, 3, 4, 4, 4, 4, 4, 4, 4, 7], device='cuda:0')\n",
      "epoch 40, time 21.48 sec\n",
      "tensor([0, 1, 0, 2, 4, 5, 1, 0, 9, 9, 0], device='cuda:0')\n",
      "epoch 50, time 26.61 sec\n",
      "tensor([0, 4, 0, 5, 4, 5, 4, 0, 4, 4, 0], device='cuda:0')\n",
      "epoch 60, time 31.75 sec\n",
      "tensor([7, 4, 5, 8, 4, 9, 4, 9, 4, 4, 5], device='cuda:0')\n",
      "epoch 70, time 36.92 sec\n",
      "tensor([0, 5, 0, 0, 4, 0, 0, 0, 0, 5, 0], device='cuda:0')\n",
      "epoch 80, time 42.07 sec\n",
      "tensor([0, 1, 0, 0, 4, 5, 6, 0, 8, 9, 0], device='cuda:0')\n",
      "epoch 90, time 47.21 sec\n",
      "tensor([10,  4,  5,  5,  4,  9,  1,  5,  4,  4, 10], device='cuda:0')\n",
      "epoch 100, time 52.36 sec\n",
      "tensor([ 0,  1,  0,  2,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 110, time 57.52 sec\n",
      "tensor([10,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 120, time 62.66 sec\n",
      "tensor([10,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 130, time 67.85 sec\n",
      "tensor([10,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 140, time 73.01 sec\n",
      "tensor([ 0,  1,  0, 10,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 150, time 78.16 sec\n",
      "tensor([ 0,  1, 10,  2,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 160, time 83.32 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 170, time 88.46 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 180, time 93.61 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 190, time 98.77 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 200, time 103.92 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 210, time 109.08 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  0,  8,  9, 10], device='cuda:0')\n",
      "epoch 220, time 114.22 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 230, time 119.37 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 240, time 124.53 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 250, time 129.68 sec\n",
      "tensor([ 0,  1, 10,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 260, time 134.82 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 270, time 139.96 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 280, time 145.11 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 290, time 150.24 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n",
      "epoch 300, time 155.40 sec\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 重要！！！\n",
    "# 此处定义net，保证每次重新训练均重新初始化net\n",
    "net = SiameseNet()\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = lr, momentum = 0.5)\n",
    "\n",
    "# 类别数\n",
    "minibatch = 11\n",
    "\n",
    "# 获取数据，X为tensor，形状为[bath_size * 3(dim) * width * hight]\n",
    "images = []\n",
    "for image in features:\n",
    "    image = cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA) # 用cv2转换大小\n",
    "    image = torch.tensor(image, dtype = torch.float, device = device)\n",
    "    images.append(image)\n",
    "X = torch.stack(images)\n",
    "X = X.view((minibatch, 3, width, height))\n",
    "\n",
    "y = torch.tensor(range(minibatch), device = device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 迭代\n",
    "epoch_num = 300\n",
    "\n",
    "#计数器，用于提前终止\n",
    "fitcount = 0\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    # 前向运算\n",
    "    y_hat = []\n",
    "    for i in range(minibatch):\n",
    "        X0 = X[i, :, :, :].view((1, 3, width, height))\n",
    "        y_hati = net(X0, X)\n",
    "        y_hat.append(y_hati)\n",
    "    y_hat = torch.stack(y_hat)\n",
    "    y_hat.device\n",
    "    \n",
    "    # 带范数惩罚的损失函数\n",
    "    norm = 0\n",
    "    for param in net.parameters():\n",
    "        norm = norm + param.norm()\n",
    "    l = loss(y_hat, y).sum() + norm * 0.05\n",
    "\n",
    "    # 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 后向梯度\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 调整超参数学习率\n",
    "    lr = 0.99 * lr\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = lr, momentum = 0.5)\n",
    "\n",
    "    # 显示分类结果\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch %d, time %.2f sec' % (epoch + 1, time.time() - start))\n",
    "        print(torch.argmax(y_hat, dim = 1))\n",
    "        \n",
    "    if sum(torch.argmax(y_hat, dim = 1) - torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], device = device)) == 0:\n",
    "        fitcount = fitcount + 1\n",
    "    else:\n",
    "        fitcount = 0\n",
    "        \n",
    "    if fitcount == 20:\n",
    "        print('epoch %d, time %.2f sec' % (epoch + 1, time.time() - start))\n",
    "        print(torch.argmax(y_hat, dim = 1))\n",
    "        print('lr = ', lr)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最先采用SGD，0.1的学习率，发现始终无法收敛  \n",
    "通过打印值发现存在震荡，于是想到可能是学习率过大  \n",
    "进一步分析，是因为训练集过小，参数对结果的影响相对变大  \n",
    "因此学习率一旦较大就会开始震荡，无法收敛  \n",
    "（可以写到报告里）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 用模型生成test文件，生成的文件名默认为test1.json\n",
    "def init_test_file(net, outname = \"test1.json\"):\n",
    "    with open(\"test.json\", \"r\") as f:\n",
    "        dic = json.loads(f.read())\n",
    "    names = list(dic)\n",
    "    num_examples = len(names)\n",
    "    for name in names:\n",
    "        path = \"Test\\\\\" + name\n",
    "        img = imageio.imread(path)\n",
    "        img = nored(img)\n",
    "        image = np.array(img[:, :, 0 : 3])\n",
    "        image = cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA)\n",
    "        image = torch.tensor(image, dtype = torch.float, device = device)\n",
    "        image = image.view(1, 3, width, height)\n",
    "        y = net(image, X)\n",
    "        label = labels[torch.argmax(y)]\n",
    "        dic[name] = idx_to_label[label]\n",
    "    json_str = json.dumps(dic)\n",
    "    with open(outname, \"w\") as f:\n",
    "        f.write(json_str)\n",
    "        \n",
    "init_test_file(net)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从test.py里面照搬的准确率验证程序  \n",
    "执行需要相同文件目录下有两个文件：  \n",
    "pred.json 正确的标注，在这里是我按照规律手工标注的  \n",
    "test.json 训练得到的标注，相对于原代码修改成了test1.json，尽量不去修改原有的文件  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 imgs missed\n",
      "class:p1\trecall:0.043478\n",
      "class:p12\trecall:0.100000\n",
      "class:p14\trecall:0.444444\n",
      "class:p17\trecall:0.476190\n",
      "class:p19\trecall:0.045455\n",
      "class:p22\trecall:0.500000\n",
      "class:p25\trecall:0.818182\n",
      "class:p27\trecall:0.270833\n",
      "class:p3\trecall:0.285714\n",
      "class:p6\trecall:0.250000\n",
      "class:p9\trecall:0.222222\n",
      "Accuracy: 0.281818\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "pred = json.load(open('pred.json', 'r'))\n",
    "label = json.load(open('test1.json', 'r'))\n",
    "\n",
    "classes = []\n",
    "correct = {}\n",
    "total = {}\n",
    "for cls in label.values():\n",
    "    if cls not in classes:\n",
    "        classes.append(cls)\n",
    "        correct[cls] = 0\n",
    "        total[cls] = 0\n",
    "classes.sort()\n",
    "\n",
    "miss = 0\n",
    "cor = 0\n",
    "for imgname in label.keys():\n",
    "    try:\n",
    "        correct[label[imgname]] += (pred[imgname] == label[imgname])\n",
    "    except:\n",
    "        miss += 1\n",
    "    total[label[imgname]] += 1\n",
    "acc_str = '%d imgs missed\\n'%miss\n",
    "for cls in classes:\n",
    "    acc_str += 'class:%s\\trecall:%f\\n'%(cls, correct[cls]/total[cls])\n",
    "    cor += correct[cls]\n",
    "acc_str += 'Accuracy: %f'%(cor/len(label))\n",
    "print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
